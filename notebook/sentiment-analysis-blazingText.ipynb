{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Blazing Text Algorithm\n",
    "In this exercise we will be using the Sagemaker Blazing Text algorithm which provides highly optimized implementations of the Word2vec and text classification algorithm. Text classification is a Natural Language Processing (NLP) task which can help determine the sentiment of a statement.\n",
    "\n",
    "We will use a public dataset for our training activity. Blazing Text algorithm requires the input to be in a standard format. This format requires a statement and its corresponding label to be in a single line. \n",
    "If your training dataset is across multiple files, then these files have to be concatenanted to create a single file with all the text lines for the algorithm.\n",
    "\n",
    "You can read more about this algorithm [here](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html).\n",
    "\n",
    "Run each cell and move on to the next cell by pressing ```Shift + Enter```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::532386544680:role/service-role/AmazonSageMaker-ExecutionRole-20220206T120699\n",
      "sagemaker-ap-southeast-2-532386544680\n"
     ]
    }
   ],
   "source": [
    "# import section\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "import csv\n",
    "import numpy as np\n",
    "# The sesssion variable will be used to access the default bucket which will host the \n",
    "# training and validation datasets along with output\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\n",
    "    role\n",
    ")  # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "prefix = \"aimlinnovate\"  # Replace with the prefix under which you want to store the data if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Review Dataset\n",
    "In order to train our model we will be using a public dataset. There are several public datasets available that could be used. One such dataset is the [Amazon Product Review dataset](http://jmcauley.ucsd.edu/data/amazon/). \n",
    "\n",
    "We will be using the Clothing, Shoes and Jewelry dataset which has 278,677 reviews.\n",
    "\n",
    "Each line in the product review file is a JSON line with the following attributes:\n",
    "* reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "* asin - ID of the product, e.g. 0000013714\n",
    "* reviewerName - name of the reviewer\n",
    "* helpful - helpfulness rating of the review, e.g. 2/3\n",
    "* **reviewText** - text of the review\n",
    "* **overall** - rating of the product (a value between 1 to 5)\n",
    "* summary - summary of the review\n",
    "* unixReviewTime - time of the review (unix time)\n",
    "* reviewTime - time of the review (raw)\n",
    "\n",
    "The 2 attributes within this dataset that are key to the sentiment analysis are:\n",
    "**reviewText** and **overall**.\n",
    "Lets download and unzip the gunzip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the gz file, overwrite if the file exists and name the file as amazon_pr.json.gz.\n",
    "!wget -q snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Clothing_Shoes_and_Jewelry_5.json.gz -O amazon_pr.json.gz\n",
    "\n",
    "# Unzip the Office Product Review file\n",
    "!gzip -fd amazon_pr.json.gz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1KLRMWW2FWPL4\", \"asin\": \"0000031887\", \"reviewerName\": \"Amazon Customer \\\"cameramom\\\"\", \"helpful\": [0, 0], \"reviewText\": \"This is a great tutu and at a really great price. It doesn't look cheap at all. I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly. A++\", \"overall\": 5.0, \"summary\": \"Great tutu-  not cheaply made\", \"unixReviewTime\": 1297468800, \"reviewTime\": \"02 12, 2011\"}\n",
      "{\"reviewerID\": \"A2G5TCU2WDFZ65\", \"asin\": \"0000031887\", \"reviewerName\": \"Amazon Customer\", \"helpful\": [0, 0], \"reviewText\": \"I bought this for my 4 yr old daughter for dance class, she wore it today for the first time and the teacher thought it was adorable. I bought this to go with a light blue long sleeve leotard and was happy the colors matched up great. Price was very good too since some of these go for over $15.00 dollars.\", \"overall\": 5.0, \"summary\": \"Very Cute!!\", \"unixReviewTime\": 1358553600, \"reviewTime\": \"01 19, 2013\"}\n",
      "{\"reviewerID\": \"A1RLQXYNCMWRWN\", \"asin\": \"0000031887\", \"reviewerName\": \"Carola\", \"helpful\": [0, 0], \"reviewText\": \"What can I say... my daughters have it in orange, black, white and pink and I am thinking to buy for they the fuccia one. It is a very good way for exalt a dancer outfit: great colors, comfortable, looks great, easy to wear, durables and little girls love it. I think it is a great buy for costumer and play too.\", \"overall\": 5.0, \"summary\": \"I have buy more than one\", \"unixReviewTime\": 1357257600, \"reviewTime\": \"01 4, 2013\"}\n",
      "{\"reviewerID\": \"A8U3FAMSJVHS5\", \"asin\": \"0000031887\", \"reviewerName\": \"Caromcg\", \"helpful\": [0, 0], \"reviewText\": \"We bought several tutus at once, and they are got high reviews. Sturdy and seemingly well-made. The girls have been wearing them regularly, including out to play, and the tutus have stood up well. Fits the 3-yr old & the 5-yr old well. Clearly plenty of room to grow. Only con is that when the kids pull off the tutus, the waste band gets twisted, and an adult has to un-tangle. But this is not difficult.\", \"overall\": 5.0, \"summary\": \"Adorable, Sturdy\", \"unixReviewTime\": 1398556800, \"reviewTime\": \"04 27, 2014\"}\n",
      "{\"reviewerID\": \"A3GEOILWLK86XM\", \"asin\": \"0000031887\", \"reviewerName\": \"CJ\", \"helpful\": [0, 0], \"reviewText\": \"Thank you Halo Heaven great product for Little Girls.  My Great Grand Daughters Love these Tutu's.  Will buy more from this seller.  Made well and cute on the girls.  Thanks for a great product.NEVER BUY FROM DRESS UP DREAMS........I will buy more as long as I don't buy from &#34;Dress Up Dreams&#34;  I never rec'd or order in FL. Only rec'd pink, the purple one was missing.  Company is a rip off.  REFUSES to make good on purchase...... Real creeps.\", \"overall\": 5.0, \"summary\": \"Grammy's Angels Love it\", \"unixReviewTime\": 1394841600, \"reviewTime\": \"03 15, 2014\"}\n",
      "{\"reviewerID\": \"A27UF1MSF3DB2\", \"asin\": \"0000031887\", \"reviewerName\": \"C-Lo \\\"Cynthia\\\"\", \"helpful\": [0, 0], \"reviewText\": \"I received this today and I'm not a fan of it but my daughter is I thought it would be puffier as it looks in the pic but it's not and the one they sent me is pink underneath and the waist band is pink which is not what I wanted due to the fact she already had the sandals she was gonna wear with it now I gotta find another pair of sandals,ima just keep it cuz she likes it.\", \"overall\": 4.0, \"summary\": \"It's ok\", \"unixReviewTime\": 1396224000, \"reviewTime\": \"03 31, 2014\"}\n",
      "{\"reviewerID\": \"A16GFPNVF4Y816\", \"asin\": \"0000031887\", \"reviewerName\": \"design maven\", \"helpful\": [0, 0], \"reviewText\": \"Bought this as a backup to the regular ballet outfit my daughter has to wear. So far, she's using it to play out her Cinderella dreams but I am sure we'll be able to use it for a recital sometime soon. The quality is just fine for the price we paid. I was not expecting a designer skirt for this price and got exactly what I paid for.\", \"overall\": 5.0, \"summary\": \"Great for dress-up and for ballet practice\", \"unixReviewTime\": 1399075200, \"reviewTime\": \"05 3, 2014\"}\n",
      "{\"reviewerID\": \"A2M2APVYIB2U6K\", \"asin\": \"0000031887\", \"reviewerName\": \"Jamie P.\", \"helpful\": [0, 0], \"reviewText\": \"Great tutu for a great price. It isn't a &#34;full&#34; or high quality skirt, but it is perfect for my daughter to wear over leggings for her little outfits.\", \"overall\": 5.0, \"summary\": \"Great value\", \"unixReviewTime\": 1356220800, \"reviewTime\": \"12 23, 2012\"}\n",
      "{\"reviewerID\": \"A1NJ71X3YPQNQ9\", \"asin\": \"0000031887\", \"reviewerName\": \"JBerger\", \"helpful\": [0, 0], \"reviewText\": \"My daughter liked this, and it with her costume, but she would have liked it to be a bit fuller.\", \"overall\": 4.0, \"summary\": \"Good\", \"unixReviewTime\": 1384041600, \"reviewTime\": \"11 10, 2013\"}\n",
      "{\"reviewerID\": \"A3EERSWHAI6SO\", \"asin\": \"0000031887\", \"reviewerName\": \"Jeffrey Hollingshead \\\"Jillian hollingshead\\\"\", \"helpful\": [7, 8], \"reviewText\": \"For what I paid for two tutus is unbeatable anywhere!  I ordered a pink and turquios and they are vibrant and beautiful! The tutu is very full! Princess style! Not cheaply made! Not cheap materia! Obviously someone made these with love and care! I paid less than 7 bucks for a tutu I and I feel proud of my self for researching to the point of finding gold!Recommend 2-6 years!My daughter is two ! Wears size 4t and this skirt ( one size ) fit perfect and will probaly be able to accommodate her quickly growing waist for some time!\", \"overall\": 5.0, \"summary\": \"WOW !! ..is all I have to say!\", \"unixReviewTime\": 1349568000, \"reviewTime\": \"10 7, 2012\"}\n"
     ]
    }
   ],
   "source": [
    "# Lets view the first 10 lines of the unzipped dataset\n",
    "!head amazon_pr.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import shuffle library to randomly shuffle the dataset to avoid bias\n",
    "from random import shuffle\n",
    "# Import the Natural Language Toolkit(NLTK). \n",
    "# The NLTK data package includes a pre-trained Punkt tokenizer for English.\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Preparing a dataset is a key step in the Machine Learning process. Preparation of a dataset is unique to the dataset that will be used to train the machine learning model. Some of the reasons data has to be prepared prior to training is to:\n",
    "* Avoid noise - Drop columns that are not relevant to the machine learning problem\n",
    "* Input requirements of Machine Learning algorithms - As we will see for the BlazingText algorithm ahead.\n",
    "* Avoid sparse data problems - Datasets can vary in quality with some having missing data which should be remediated.\n",
    "\n",
    "In our example, we will:\n",
    "* Create a Pandas Dataframe and load the Product Review file made up of JSONLines.\n",
    "* Drop Columns that are not relevant to the business problem\n",
    "* Introduce a new label column based on the value of an existing column. BlazingText algorithm requires the label to be prefixed by **\\_\\_label\\_\\_**\n",
    "* Do a random shuffle to ensure remove bias from the data\n",
    "* Split the training data into 90:10 training and validation dataset\n",
    "\n",
    "**Note:**\n",
    "For ``supervised`` mode, the training/validation file should contain a training sentence per line along with the labels. Labels are words that are prefixed by the string ``__label__``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  This is a great tutu and at a really great pri...        5\n",
       "1  I bought this for my 4 yr old daughter for dan...        5\n",
       "2  What can I say... my daughters have it in oran...        5\n",
       "3  We bought several tutus at once, and they are ...        5\n",
       "4  Thank you Halo Heaven great product for Little...        5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data_df = pd.read_json('amazon_pr.json', lines=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "# Retain only the reviewText Column and the Overall column. \n",
    "# The Overall column stores the rating provided by the reviewer on a scale from 1-5\n",
    "\n",
    "data_df=data_df.drop(['reviewerID', 'asin','reviewerName','helpful','summary','unixReviewTime','reviewTime'], axis=1)\n",
    "# Display the top5 rows of the dataframe\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    False\n",
       "overall       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any of the values are NULL\n",
    "# A value of True suggests that are are NULLs. These values can either be set or removed depending \n",
    "# on the number of rows affected.\n",
    "# A value of False suggests that there are no empty values in both dataframe columns\n",
    "data_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method label_create that will create a categorisation based on the overall rating field.\n",
    "# You can choose your own categorisation. \n",
    "# For this activity we have followed the below label creation logic:\n",
    "    # BlazingText algorithm requires the label value to be prefixed by \"__label__\"\n",
    "    # If the overall (rating) is 1 or 2 Set the Label to __label__1 (or Negative Sentiment)\n",
    "    # If the overall (rating) is 3 or 4 Set the Label to __label__2 (or Neutral Sentiment)\n",
    "    # If the overall (rating) is 5 Set the Label to __label__3 (or Positive Sentiment)\n",
    "# You could change this logic to create your own text labels(classifications)\n",
    "\n",
    "def label_create(row):\n",
    "    if row['overall'] == 1 or row['overall'] == 2 :\n",
    "        val = '__label__1'\n",
    "    elif row['overall'] == 3 or row['overall'] == 4 :\n",
    "        val = '__label__2'\n",
    "    elif row['overall'] == 5 :\n",
    "        val = '__label__3'\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe column called 'label' and use the label_create method to set values\n",
    "data_df['label'] = data_df.apply(label_create, axis=1)\n",
    "\n",
    "# Drop the overall column from the dataframe as this is now replaced with label column\n",
    "data_df=data_df.drop(['overall'], axis=1)\n",
    "\n",
    "# Change the reviewText to lowercase\n",
    "data_df[\"reviewText\"] = data_df[\"reviewText\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__3    163240\n",
       "__label__2     88782\n",
       "__label__1     26655\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once done lets look at text classification spread.\n",
    "# For an effective model, the model should ideally be trained on a dataset with adequate representations\n",
    "# from each label\n",
    "\n",
    "data_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this stage it is a good idea to shuffle and then split your training dataset \n",
    "# into training and validation dataset.\n",
    "\n",
    "# Use 90:10 split for training:validation\n",
    "fractions = np.array([0.9, 0.1])\n",
    "# shuffle your input\n",
    "data_df = data_df.sample(frac=1) \n",
    "# split into 2 parts\n",
    "train, val = np.array_split(data_df, (fractions[:-1].cumsum() * len(data_df)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13203</th>\n",
       "      <td>loved the bra, but it was too big so it was re...</td>\n",
       "      <td>__label__3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170271</th>\n",
       "      <td>this is sooo not woman's hat. when this hat ar...</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205838</th>\n",
       "      <td>i really like this necklace and it really adds...</td>\n",
       "      <td>__label__3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231572</th>\n",
       "      <td>i'm happy with the quality of the item. feels ...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128866</th>\n",
       "      <td>i've wanted this for quite awhile. earrings ar...</td>\n",
       "      <td>__label__3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText       label\n",
       "13203   loved the bra, but it was too big so it was re...  __label__3\n",
       "170271  this is sooo not woman's hat. when this hat ar...  __label__1\n",
       "205838  i really like this necklace and it really adds...  __label__3\n",
       "231572  i'm happy with the quality of the item. feels ...  __label__2\n",
       "128866  i've wanted this for quite awhile. earrings ar...  __label__3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of train dataframe.\n",
    "# Notice how the index values have been shuffled (out of order)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 csv files, val (validation) and train(training) to start training the ML model\n",
    "val.to_csv('val.csv', mode='w', sep=' ', columns=['label','reviewText'], index=False, header=False)\n",
    "train.to_csv('train.csv', mode='w', sep=' ', columns=['label','reviewText'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Training and Validation channel\n",
    "Once the dataset is shuffled and split, the training file should be uploaded to the train channel and the validation dataset should be uploaded under the validation channel (Using a validation channel is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 669 ms, sys: 564 ms, total: 1.23 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Set the channel names\n",
    "train_channel = prefix + \"/train\"\n",
    "validation_channel = prefix + \"/validation\"\n",
    "\n",
    "# Upload the training and validation dataset to the default bucket\n",
    "sess.upload_data(path=\"train.csv\", bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path=\"val.csv\", bucket=bucket, key_prefix=validation_channel)\n",
    "# Set the location for the training & validation data.\n",
    "s3_train_data = \"s3://{}/{}\".format(bucket, train_channel)\n",
    "s3_validation_data = \"s3://{}/{}\".format(bucket, validation_channel)\n",
    "# Set the location for the output data. This is where the model once generated will be stored.\n",
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Container image\n",
    "Get the container image name for the Sagemaker BlazingText algorithm in the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 544295431143.dkr.ecr.ap-southeast-2.amazonaws.com/blazingtext:1 (ap-southeast-2)\n"
     ]
    }
   ],
   "source": [
    "# Get the container image name for the Sagemaker BlazingText algorithm\n",
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print(\"Using SageMaker BlazingText container: {} ({})\".format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the resource configuration \n",
    " Define the resource configuration and hyperparameters to perform the text classification using ``supervised`` mode on a ``ml.c4.4xlarge`` instance.\n",
    "\n",
    "The [algorithm documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext_hyperparameters.html) for the complete list of hyperparameters. As this is a Text Classification problem, look for Text Classification Hyperparameters.\n",
    "\n",
    "Sagemaker allows performing [hyperparameter tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext-tuning.html) to find the best set of hyperparamters for the machine learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.4xlarge\",\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters={\n",
    "        \"mode\": \"supervised\",\n",
    "        \"epochs\": 5,\n",
    "        \"min_count\": 2,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"vector_dim\": 10,\n",
    "        \"early_stopping\": True,\n",
    "        \"patience\": 4,\n",
    "        \"min_epochs\": 5,\n",
    "        \"word_ngrams\": 2,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other configurations\n",
    "Set the training inputs and data channels prior to running training the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Once the input channels are defined and the hyperparameters are set the ML training can begin. \n",
    "The ``fit`` method is run to start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 04:22:59 Starting - Starting the training job...\n",
      "2022-02-07 04:23:23 Starting - Preparing the instances for trainingProfilerReport-1644207779: InProgress\n",
      "......\n",
      "2022-02-07 04:24:23 Downloading - Downloading input data...\n",
      "2022-02-07 04:24:48 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[02/07/2022 04:24:51 WARNING 140190206858624] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[02/07/2022 04:24:51 WARNING 140190206858624] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[02/07/2022 04:24:51 INFO 140190206858624] nvidia-smi took: 0.025214195251464844 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[02/07/2022 04:24:51 INFO 140190206858624] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[02/07/2022 04:24:51 INFO 140190206858624] Processing /opt/ml/input/data/train/train.csv . File size: 78.83177280426025 MB\u001b[0m\n",
      "\u001b[34m[02/07/2022 04:24:51 INFO 140190206858624] Processing /opt/ml/input/data/validation/val.csv . File size: 8.695636749267578 MB\u001b[0m\n",
      "\u001b[34mRead 10M words\u001b[0m\n",
      "\u001b[34mRead 15M words\u001b[0m\n",
      "\u001b[34mNumber of words:  104198\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/val.csv\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0305  Progress: 38.95%  Million Words/sec: 41.13 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0278  Progress: 44.44%  Million Words/sec: 41.31 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0250  Progress: 49.96%  Million Words/sec: 41.44 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0223  Progress: 55.45%  Million Words/sec: 41.54 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0196  Progress: 60.90%  Million Words/sec: 41.59 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0168  Progress: 66.41%  Million Words/sec: 41.66 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0141  Progress: 71.90%  Million Words/sec: 41.72 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0111  Progress: 77.81%  Million Words/sec: 41.84 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0083  Progress: 83.47%  Million Words/sec: 41.97 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0055  Progress: 89.02%  Million Words/sec: 42.03 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0027  Progress: 94.60%  Million Words/sec: 42.09 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: -0.0000  Progress: 100.00%  Million Words/sec: 42.07 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.768408\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 40.04 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 40.04\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 1.94\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.8232\u001b[0m\n",
      "\u001b[34mNumber of train examples: 250809\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.7684\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 27868\u001b[0m\n",
      "\n",
      "2022-02-07 04:25:23 Uploading - Uploading generated training model\n",
      "2022-02-07 04:25:23 Completed - Training job completed\n",
      "Training seconds: 58\n",
      "Billable seconds: 58\n"
     ]
    }
   ],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Accuracy\n",
    "The training and validation accuracy can be noted in the above run by looking at the ```train_accuracy``` and ```validation_accuracy``` . \n",
    "\n",
    "**Note:**\n",
    "While the quality training dataset plays an important role in increasing the accuracy of the ML model, the performance of the ML model can be improved by performing automatic model tuning with SageMaker. For more information, see [here](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model\n",
    "Now that the model is trained, we can deploy this model as a SageMaker Endpoint using the SageMaker hosting services. \n",
    "This is quite easily done using ``model.deploy`` command or via the SageMaker console.\n",
    "\n",
    "This will take a few minutes to execute.\n",
    "\n",
    "Note: SageMaker now supports deploying a [serverless endpoint in preview](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html) providing a cost effective pay per use cost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "text_classifier = bt_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=JSONSerializer(), endpoint_name=\"bt-nlp-endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the SageMaker Endpoint\n",
    "Once deployed, the SageMaker Endpoint can be invoked from a Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': ['I love this product . I would order it again', 'I am not sure if I like this product . I probably do .']}\n",
      "[\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__3\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.9555298686027527\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__2\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.9004751443862915\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I love this product. I would order it again\",\n",
    "    \"I am not sure if I like this product. I probably do.\"\n",
    "]\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [\" \".join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "payload = {\"instances\": tokenized_sentences}\n",
    "print (payload)\n",
    "response = text_classifier.predict(payload)\n",
    "\n",
    "\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Once the endpoint is deployed, it can be invoked by an Lambda function fronted by an API gateway. The API calls to the SageMaker Endpoint can be secured using the AWS security best practices."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
